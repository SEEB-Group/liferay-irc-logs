--- Log opened Mon Sep 15 00:00:20 2014
02:37 < goku_:#liferay> hi ,when am using the action button (with one option) on the liferay search container  ,it showing as more information ,the action button was not coming . how to show the action button even if there only one option?
--- Log opened Mon Sep 15 03:21:23 2014
03:21 -!- ServerMode/#liferay [+ns] by cameron.freenode.net
03:21 [Users #liferay]
03:21 [@bijoo] 
03:21 -!- Irssi: #liferay: Total of 1 nicks [1 ops, 0 halfops, 0 voices, 0 normal]
03:21 -!- Channel #liferay created Mon Sep 15 03:21:28 2014
03:21 -!- Irssi: Join to #liferay was synced in 6 secs
03:59 -!- ServerMode/#liferay [-o bijoo] by cameron.freenode.net
03:59 !cameron.freenode.net *** Notice -- TS for #liferay changed from 1410765688 to 1257972006
03:59 -!- ServerMode/#liferay [+ct-s] by cameron.freenode.net
03:59 -!- ServerMode/#liferay [+o ChanServ] by cameron.freenode.net
03:59 -!- cameron.freenode.net changed the topic of #liferay to: Liferay Community Discussion Channel! *THIS CHANNEL IS LOGGED* (Log: http://goo.gl/SMte1N) Plz be patient - timezones matter :)  Please nominate Liferay! http://goo.gl/bIspUh Liferay 6.2 GA2 RELEASE http://goo.gl/uclhsq   Forum: http://forums.liferay.com Homepage: http://liferay.org User Groups http://goo.gl/WFVtPe Nightly build http://goo.gl/vQngHn
05:56 < Yam`:#liferay> hi
08:21 < Axxell:#liferay> Hey guys trying to ad to liferay 6.2 web content listing the ability to sort articles by title but i cant get it to work
08:21 < Axxell:#liferay> any clues?
08:31 < Axxell:#liferay> the error i get is: 12:17:15,247 ERROR [http-bio-8080-exec-7][JDBCExceptionReporter:82] Unknown column 'title' in 'order clause'
08:31 < Axxell:#liferay> older versions used the "title" column as a orderbycol
08:40 < Axxell:#liferay> i can sort by urlTitle but that doesnt help much
08:42 < Yam`:#liferay> Has somebody ever exported lportal base in an other computer and faced issues with groups?
08:55 -!- mode/#liferay [+o jhf] by ChanServ
09:28 < jardineworks_:#liferay> topolik, you around?
09:35 < Urug_:#liferay> I have got finished Liferay application running on single machine using bundled Tomcat server and MySQL db. Everything is setup as default. My task is to create another server instance which is going to be one-to-one replica of the existing one working as backup server. So these servers must be always sychronized. I've got zero experience with clustering or replicating. I am looking for any advice, direction or general information how t
09:37 < jardineworks_:#liferay> Urug_, Liferay clustering is easy. If you support multicast it is even easier. One minute, I think I have the instructions written down.
09:38 < jardineworks_:#liferay> Urug_, in your portal-ext -- add the following
09:38 < jardineworks_:#liferay> cluster.link.enabled=true
09:38 < jardineworks_:#liferay> cluster.link.autodetect.address=<some-address>:<some-port>
09:38 < jardineworks_:#liferay> lucene.replicate.write=true
09:39 < jardineworks_:#liferay> for the address and port, I think I used my database ip and 3306 (for MySQL)
09:39 < jardineworks_:#liferay> that will allow the ehcache and search index to remain in synch
09:40 < jardineworks_:#liferay> but if your setup is active passive, meaning the "backup instance" is never used unless the first instance goes down then you might not even need clustering. Clustering is only really necessary when both nodes are serving requests. If the backup only kicks in when the other node is down, it might be enough for them simply to be connected to the same database
09:40 < Yam`:#liferay> Is there a property file or something that links the usergroups to the portal?
09:41 < jardineworks_:#liferay> Yam`, the user groups that are created in the portal? or external user groups?
09:41 < Yam`:#liferay> jardineworks_, the user groups created in the portal
09:42 < Yam`:#liferay> because I've created user groups in the portal and exported the lportal database to another computer, I've got the user groups in the database but they are not displayed in the portal
09:42 < Yam`:#liferay> "no user groups were found"
09:43 < jardineworks_:#liferay> Yam`, go to the Server Administration .. clear the caches, and rebuild the serach indices.
09:43 < jardineworks_:#liferay> the user groups are created with in a portal instance (companyId) so exporting the database in its entirety will move everything -- or at least it should
09:44 < Yam`:#liferay> jardineworks_, the database cache ?
09:44 < Yam`:#liferay> or all of them ?
09:44 < jardineworks_:#liferay> Yam`, anything that is in that page
09:45 < jardineworks_:#liferay> the worst that will happen is that the site will be slow for a minute while that stuff is rebuilt.
09:45 < Yam`:#liferay> ok thanks
09:45 < jardineworks_:#liferay> Yam`, lemme know if that helps or not
09:48 < Yam`:#liferay> It worked, thanks jardineworks_, I've been struggling with this for half a day haha
09:48 < jardineworks_:#liferay> Yam`, I think I spent about half a day on it the first time I tried to solve that one :)
09:50 < Yam`:#liferay> Same here haha
09:55 < Urug_:#liferay> So it should be only about running another Liferay server and changing a Liferay configuration little bit. I mean I don't have to deal with some configuration out of Liferay sandbox.
09:56 < Urug_:#liferay> What about existing data are they going to be replicated?
09:56 < Urug_:#liferay> And what about liferay repository (files and documents)?
09:57 < jardineworks_:#liferay> Urug_, are you sharing the same database between both nodes?
09:59 < Urug_:#liferay> I quess they should be separated so  one of them can really work as backup.
09:59 < jardineworks_:#liferay> ah
09:59 < jardineworks_:#liferay> Urug_, ok so that is a different story. That sounds more like you are setting up a DR (disaster recovery)
10:00 < jardineworks_:#liferay> Which is not really a situation for clustering
10:05 < Urug_:#liferay> That's probably more appropriate term I quess, but basically two liferay instaces running in cluster could work the same way if active passive setup is not requierement, couldn't they?
10:07 < Urug_:#liferay> The requierement is to have access to application with all data up to date if one fo the erver will fail.
10:07 < Urug_:#liferay> *one of the servers
10:09 < jardineworks_:#liferay> Urug_, In that case an active passive cluster can be configured. Clearly you need at least 2 Liferay servers, but is the requirement also to have 2 database servers (also in active passive mode)?
10:10 < jardineworks_:#liferay> If so, then you probably has a proxy to the LR servers ... say server .200 that routes requests to 201, and 202. Both those servers would be configured for a secondary proxy (say 210) that would route requests to 211, 212 -- each being a datsabase. So you would handle the liferay clustering on 201 and 202 (using the stuff above), and you would configure MySQL (check their docs) to be clustered as well
10:11 < jardineworks_:#liferay> the proxy load balancer algorithm would basically always route traffic to 201 unless the health check failed, in which case it would send the request to 202. But you leave that control to the proxy
10:12 < jardineworks_:#liferay> 202 and 212 are both up and running ... so they are synchronized with 201 and 211, but the passive piece would be them just sitting around on the bench waiting for their turn to play.
10:15 < winem_:#liferay> hello, I'm a bit confused regarding liferay and java 8. several people in the community says that it's working fine with CE 6.2.1 but is it already supported or not? I can't find an official statement from liferay
10:18 < jardineworks_:#liferay> winem_, not supported yet I don't think
10:18 < jardineworks_:#liferay> Java 8 was release after 6.2
10:19 < jardineworks_:#liferay> winem_, best best is to stick with Java 7 for now
10:19 < winem_:#liferay> ok
10:26 -!- mode/#liferay [+o _jhf_] by ChanServ
10:33 < Urug_:#liferay> Having two databases is the requirement, however they don't have to be active passive, both of them can be used for reading/writing anytime, but they must stay synced. If one fo them fails, it must be (automatically) re-synced after the recovery.
10:34 < jardineworks_:#liferay> Urug_, ok. That part though would have to be managed by MySQL clustering which is configured and managed outside of Liferay. The clustering that Liferay manages through configuration only relates to resources that it manages -- namely, the search index and the ehcache (or whatever cache implementation you choose to use)
10:37 < Yam`:#liferay> jardineworks_, have you ever done a custom.css and having trouble with the ">" character (icon-like) of accordions tabs?
10:39 < Urug_:#liferay> Thank you very much it helped me to create a better picture. And what about the repository, the default is using file system, I need to replicate them as well...
10:40 < jardineworks_:#liferay> Urug_, I would configure that to use a NFS (network file share) and the make sure you have the appropriate backup copies and stuff done using file system triggers or cron jobs to a alternate directory.
10:40 < winem_:#liferay> It's as far as I know also not possible in liferay. but you can set the repositories.root.path to a location on a NFS share
10:40 < jardineworks_:#liferay> or however the ops guys handle that stuff :)
10:41 < winem_:#liferay> *ping* here's a ops guy :)
10:41 < jardineworks_:#liferay> haha
10:42 < jardineworks_:#liferay> Yam`, because that is also a character used to close an html tag, you should probably specify it as an HTML entity number rather than the character itself
10:45 < Yam`:#liferay> jardineworks_, do you know this character's html tag?
10:48 < jardineworks_:#liferay> >	greater than	&gt;	&#62;
10:48 < jardineworks_:#liferay> Yam`, http://www.w3schools.com/html/html_entities.asp
10:49 < Yam`:#liferay> is that so? I thought it was a special character
10:49 < Urug_:#liferay> &gt;
10:56 < jardineworks_:#liferay> Yam`, I'm not sure what you are doing :)... an example might help
10:56 < Urug_:#liferay> Maybe I could use another repository implementation such as Jackrabbit and use the same MySQL DB as I am using for Liferay as DataStore. That way I would have to deal only with DB replication.
10:56 < jardineworks_:#liferay> Urug_, both options for sure
10:57 < jardineworks_:#liferay> jackrabbit by default writes to the LIFERAY_HOME/data folder
10:57 < jardineworks_:#liferay> so you would need to configure it to write elsewhere.
11:14 < Yam`:#liferay> jardineworks_, it wasn't a character but an icon, there's no problem actually
11:15 < Urug_:#liferay> Well but when I am simply replicating data on DB implementation level, there could occur some problems with inconsistency between database and application data in memory (eg. some memory caches?) am I right?
11:16 < jardineworks_:#liferay> Urug_, shouldn't be if you have all the replication set up.
11:16 < jardineworks_:#liferay> Urug_, for example...
11:19 < jardineworks_:#liferay> Urug_, you retrieve a list of users using the UserLocalServiceUtil class. If the cache is not yet primed, then the result of this call will load data from the database and then place it into the cache. The next time you use the UserLocalServiceUtil, it will detect the cache and use it first. Now, with a cache in place, you choose to ADD a user. That action will invalidate the cache. Cache level actions are replicated in the c
11:19 < jardineworks_:#liferay> luster. So if you add the user on Server A, the cache is expired, and a cache expiration message sent to Server B. Your next request retrieves the list of users again (on Server A) whcih rebuilds the cache, which causes a cache event message to be sent to B and the cache is updated so that your next request that goes to B displays the same state as A
11:31 < Urug_:#liferay> These invalidation messages are handled by cache implementation (using some clustering setting taken from liferay configuration) I suppose, not by Liferay itself.
11:31 < winem_:#liferay> and the cache will be renewed when you add a new user or when someone calls the list of users?
11:31 < Urug_:#liferay> So for example if I use Jackrabbit I only have to make sure it uses the same cache.
11:32 < jardineworks_:#liferay> Urug_, Liferay has a whole set of classes in the API that are injected when you enable clustering. So basically, Liferay handles the notification of cache expiration, but its the cache implementation (I beleive) that does the actual state change.
11:33 < jardineworks_:#liferay> Urug_, Jackrabbit would be independent of it... its just a storage mechanism right? The *ServiceUtil classes for the Document Library would manage the cache addition, removal, etc.
11:33 < jardineworks_:#liferay> winem_, I'd have to look at the source to say for sure but I think it is on next access... lazy load model.
11:34 < winem_:#liferay> no need to spend time on it. but I guess you're right. at least, this is what I would expect :)
11:34 < Urug_:#liferay> My concern is that you can for example add files to repository using different API than Liferay's. If liferay would be in charge of handeling these notifications, the cache clustered wouldn't be notified and therefore possibly out of sync.
11:35 < jardineworks_:#liferay> Urug_, correct.
11:36 < winem_:#liferay> this would require some communication to liferay (via an API) in my opinion. would work using hooks e.g.
11:36 < jardineworks_:#liferay> Urug_, but there is only two ways to get around that
11:36 < jardineworks_:#liferay> 1. Don't do it. :)
11:36 < jardineworks_:#liferay> 2. Have an external cache server/service that all the systems communicate with
11:37 < jardineworks_:#liferay> actually, I'm not even sure the server would do it ..
11:37 < jardineworks_:#liferay> winem_, Right.. third option...
11:37 < jardineworks_:#liferay> make the other applications use the Liferay services api to add/remove/get items
11:37 < jardineworks_:#liferay> rathan that JCR directly.
11:37 < jardineworks_:#liferay> rather*
11:38 < winem_:#liferay> JCR = jackrabbit?
11:39 < jardineworks_:#liferay> Java Content Repository
11:39 < jardineworks_:#liferay> oh whcih Jackrabbit is one of them
11:39 < jardineworks_:#liferay> JCR is a standard... JSR-170 was one of them.. I think 300 or soemthing is the latest.
11:40 < winem_:#liferay> which alternatives do you have and which one would you prefer? the default setup seems to use lucene and jackrabbit. is this the "best practice" and recommended or would you choose some alternatives?
11:40 < jardineworks_:#liferay> winem_, I'm not expert on JCR... to be honest, most of the time I use a NFS.
11:41 < winem_:#liferay> we will use it for the content store too :)
11:41 < jardineworks_:#liferay> lucene is good enough most of the time but I know that the SOLR plugin is popular... easier to write queries using SOLR than it is Lecene.
11:41 < jardineworks_:#liferay> though I believe the next release of LR is going to support ES ... and I think there is a community plugin that was done by a partner as well -- haven't had a chance to check it out yet.
11:42 < winem_:#liferay> first reaction: thank good that I have Java developers who I can trust... then I remembered that I'd like to write my own portlets..
11:43 < jardineworks_:#liferay> winem_, if you're an ops guy then I would focus in on stuff that makes your life easier :)
11:43 < winem_:#liferay> this is my job :)
11:45 < winem_:#liferay> one of the developers told me "a lazy admin is a good admin" when I started to work as an admin... I laughed at him and did not understood what he mean. Now I think that he was damn right and it's my job to make myself  superfluous :)
11:46 < winem_:#liferay> but, just to be sure that I get it right. Lucene is used for indexes and internal stuff, e.g. and jack rabbit is used for what?
11:46 < winem_:#liferay> I'm not sure which data are written to the jackrabbit folder and which ones in the document folder. the last one contains the css and so on. but wherefore do we need the jackrabbit?
11:49 < jardineworks_:#liferay> winem_, lucene is the default "search engine". So anything that is "indexed" and is searcheable has a record dumped into lucene. You can use a tool called "Luke" to inspect the index and see the records, run (lucene) queries etc,
11:49 < jardineworks_:#liferay> jackrabbit is a content repo... so its a way of storing assets, documents etc.
11:49 < jardineworks_:#liferay> So when you save a PDF file to the document library, by default it would be written to the file system.. as a regular file.
11:50 < jardineworks_:#liferay> the link that you get basically links to the file on disk.
11:50 < jardineworks_:#liferay> if you configure jackrabbit, then the save goes to the "jackrabbit" repo... which by default is configured to write to disk of course, BUT you could configure jackrabbit to write elsewhere --- for example, as BLOBs in a database, or to a NFS, etc.
11:51 < jardineworks_:#liferay> the nice thing about JCR is you can connect multiple JCR compliant applications to the same repo.
11:51 < winem_:#liferay> oh, now it starts to become interesting..
11:51 < jardineworks_:#liferay> so you could have a .. I dunno... OpenCMS application accessing the same repo as Liferay.
11:52 < winem_:#liferay> so, the stupid admin would configure the resource.repositories.root and set it to a dir on a mounted nfs volume
11:53 < winem_:#liferay> but it sounds like you can tell jackrabbit to store it on a NFS... and I guess this will have several benefits
11:55 < jardineworks_:#liferay> winem_, I've never done that, but I believe so.
11:55 < jardineworks_:#liferay> jackrabbit basically removes the coupling from Liferay to the disk
11:56 < winem_:#liferay> you never configured jackrabbit to store the stuff on a NFS or you never set the resource.repositories.root to a NFS volume?
11:56 < jardineworks_:#liferay> the "JCR" becomes an interface that it uses to save files ... but the acutal implementation is blackback to liferay. It doesn't care... it just adheres to the contract.
11:57 < jardineworks_:#liferay> winem_, either. but I have done maintenance on a project that used Jackrabbit and a NFS ... so I do believe that is a valid configuration.
11:57 < winem_:#liferay> ok, will check this. a NFS volume will be one of the key elements for a new project
12:01 < Urug_:#liferay> I would recommed look at ModeShape implementation
12:02 < jardineworks_:#liferay> Urug_, wassat?
12:03 < Urug_:#liferay> JCR impl from JBoss
12:04 < jardineworks_:#liferay> Urug_, cool.. thanks I'll check it out :)
12:13 < Urug_:#liferay> Returning to original problem ... aren't there tools which would basically keep servers synced by creating snapshots/diffs of entire server (probably without memory) and replicating them realtime?
12:16 < Urug_:#liferay> Like something that suits that Disaster recovery situation better...
12:16 < winem_:#liferay> you can search for shared filesystems like hadoop
12:17 < winem_:#liferay> this is "very advanced stuff" but should fit your needs
12:17 < winem_:#liferay> you have one "master-storage" and as much clients as you want to. and all of them contain a snapshot of the real data
12:19 < winem_:#liferay> and it's a project from the apache foundation :)
12:22 -!- jhf changed the topic of #liferay to: Liferay Community Discussion Channel! *THIS CHANNEL IS LOGGED* (Log: http://goo.gl/SMte1N) Plz be patient - timezones matter :)  Please vote Liferay! http://awards.cmscritic.com/vote Liferay 6.2 GA2 RELEASE http://goo.gl/uclhsq   Forum: http://forums.liferay.com Homepage: http://liferay.org User Groups http://goo.gl/WFVtPe Nightly build http://goo.gl/vQngHn
12:23 < Urug_:#liferay> thanks i will look into it
12:25 < Urug_:#liferay> I have already heard about it on SpringDeveloper YT channel...
12:30 < Urug_:#liferay> But it looks like it will be beyond my credit rating :)
12:41 < Urug_:#liferay> lol I googled for: "hadoop disaster recovery". Found link "Hadoop Backup, Disaster Recovery & Service Availability" which results in "503 Service Unavailable" :)
15:09 < stefkos:#liferay> anyone here?
15:10 < jardineworks_:#liferay> sorta
15:10 < jardineworks_:#liferay> :)
15:10 < stefkos:#liferay> :)
15:10 < stefkos:#liferay> dont want to interrupy
15:10 < stefkos:#liferay> -y +t
15:10 < stefkos:#liferay> I wrote an app, but... action or actionListeners doesnt work
15:11 < stefkos:#liferay> I see that something is going on, but bean functions are not called
15:11 < jardineworks_:#liferay> you mean you wrote an MVC portlet and the portlet:action doesn't work?
15:11 < stefkos:#liferay> its more like simple j2ee app then mvc
15:12 < stefkos:#liferay> but for example
15:12 < stefkos:#liferay> <p:commandLink id="ajax" update="growl" actionListener="#{fileView.listenerAddDisplay}">
15:12 < stefkos:#liferay>         <h:outputText value="Ajax Submit" />
15:12 < stefkos:#liferay>     </p:commandLink>
15:12 < jardineworks_:#liferay> but you created a plugin right?
15:12 < stefkos:#liferay> this doesnt work
15:12 < stefkos:#liferay> yeah
15:12 < jardineworks_:#liferay> oh -- JSF portlet
15:12 < stefkos:#liferay> yep
15:12 < stefkos:#liferay> cute:0
15:12 < jardineworks_:#liferay> sorry -- outta my wheel house on this one.
15:12 < jardineworks_:#liferay> I haven't done anything with JSF.
